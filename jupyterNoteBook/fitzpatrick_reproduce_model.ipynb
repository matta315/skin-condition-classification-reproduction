{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7966577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4fc8f7",
   "metadata": {},
   "source": [
    "# 1. Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd651f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = \"../data/processed/images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a33a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to CPI\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a59b3",
   "metadata": {},
   "source": [
    "# 2. DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791666b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitzpatrickDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, target_condition=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file: Path to the CSV file with annotations\n",
    "            root_dir: Directory with all the images\n",
    "            transform: Optional transform to be applied on a sample\n",
    "            target_condition: If specified, only include this skin condition or list of conditions\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Verify image paths exist\n",
    "        self.data_frame['image_exists'] = self.data_frame['image_path'].apply(os.path.exists)\n",
    "        self.data_frame = self.data_frame[self.data_frame['image_exists']]\n",
    "        self.data_frame = self.data_frame.drop('image_exists', axis=1)\n",
    "        \n",
    "        # Filter by condition if specified\n",
    "        if target_condition is not None:\n",
    "            if isinstance(target_condition, list):\n",
    "                # Filter for multiple conditions\n",
    "                self.data_frame = self.data_frame[self.data_frame['label'].isin(target_condition)]\n",
    "            else:\n",
    "                # Filter for a single condition\n",
    "                self.data_frame = self.data_frame[self.data_frame['label'] == target_condition]\n",
    "        \n",
    "        # Convert three_partition_label to binary (malignant vs. non-malignant)\n",
    "        self.data_frame['binary_label'] = self.data_frame['three_partition_label'].apply(\n",
    "            lambda x: 1 if x == 'malignant' else 0\n",
    "        )\n",
    "        \n",
    "        # Group skin types into light (1-3) and dark (4-6)\n",
    "        self.data_frame['skin_group'] = self.data_frame['fitzpatrick_scale'].apply(\n",
    "            lambda x: 0 if x <= 3 else 1  # 0 for light, 1 for dark\n",
    "        )\n",
    "        \n",
    "        # Create a mapping for unique conditions\n",
    "        self.unique_conditions = self.data_frame['label'].unique()\n",
    "        self.condition_to_idx = {condition: idx for idx, condition in enumerate(self.unique_conditions)}\n",
    "        \n",
    "        # Add multi-class label\n",
    "        self.data_frame['condition_idx'] = self.data_frame['label'].apply(lambda x: self.condition_to_idx[x])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        img_path = self.data_frame.iloc[idx]['image_path']\n",
    "        \n",
    "        try:\n",
    "            # Use PIL to load image\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a placeholder image if loading fails\n",
    "            image = Image.new('RGB', (224, 224), color='gray')\n",
    "        \n",
    "        # Get labels\n",
    "        binary_label = float(self.data_frame.iloc[idx]['binary_label'])  # Convert to float\n",
    "        skin_type = int(self.data_frame.iloc[idx]['fitzpatrick_scale'])\n",
    "        skin_group = int(self.data_frame.iloc[idx]['skin_group'])\n",
    "        condition_idx = int(self.data_frame.iloc[idx]['condition_idx'])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Return all necessary information\n",
    "        return image, binary_label, skin_type, skin_group, condition_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3393c",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a31e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=32, target_condition=None, max_samples=None):\n",
    "    \"\"\"\n",
    "    Load and prepare the datasets with optimization for speed\n",
    "    \"\"\"\n",
    "    # Define transforms with smaller image size\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # Smaller size for faster training\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = FitzpatrickDataset(\n",
    "        csv_file=os.path.join(DATA_PATH, 'train_split.csv'),\n",
    "        root_dir=DATA_PATH,\n",
    "        transform=transform,\n",
    "        target_condition=target_condition\n",
    "    )\n",
    "    \n",
    "    val_dataset = FitzpatrickDataset(\n",
    "        csv_file=os.path.join(DATA_PATH, 'val_split.csv'),\n",
    "        root_dir=DATA_PATH,\n",
    "        transform=transform,\n",
    "        target_condition=target_condition\n",
    "    )\n",
    "    \n",
    "    test_dataset = FitzpatrickDataset(\n",
    "        csv_file=os.path.join(DATA_PATH, 'test_split.csv'),\n",
    "        root_dir=DATA_PATH,\n",
    "        transform=transform,\n",
    "        target_condition=target_condition\n",
    "    )\n",
    "    \n",
    "    # Optionally limit the number of samples\n",
    "    if max_samples is not None:\n",
    "        # Simple random sampling for testing\n",
    "        if len(train_dataset) > max_samples:\n",
    "            indices = torch.randperm(len(train_dataset))[:max_samples]\n",
    "            train_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
    "        if len(val_dataset) > max_samples // 5:\n",
    "            indices = torch.randperm(len(val_dataset))[:max_samples // 5]\n",
    "            val_dataset = torch.utils.data.Subset(val_dataset, indices)\n",
    "        if len(test_dataset) > max_samples // 5:\n",
    "            indices = torch.randperm(len(test_dataset))[:max_samples // 5]\n",
    "            test_dataset = torch.utils.data.Subset(test_dataset, indices)\n",
    "    \n",
    "    # Create dataloaders with fewer workers and persistent_workers=False\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Use 0 workers to debug\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=0,  # Use 0 workers to debug\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=0,  # Use 0 workers to debug\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Get unique conditions (handle the case when train_dataset is a Subset)\n",
    "    if isinstance(train_dataset, torch.utils.data.Subset):\n",
    "        # Get the original dataset\n",
    "        original_dataset = train_dataset.dataset\n",
    "        unique_conditions = original_dataset.unique_conditions\n",
    "    else:\n",
    "        unique_conditions = train_dataset.unique_conditions\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, unique_conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81bddab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a smaller dataset with focus on key conditions\n",
    "#target_conditions = ['psoriasis', 'squamous_cell_carcinoma', 'lichen_planus']\n",
    "train_loader, val_loader, test_loader, unique_conditions = load_data(\n",
    "    batch_size=32,\n",
    "    target_condition=None,\n",
    "    max_samples=None  # Limit total samples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca43ac",
   "metadata": {},
   "source": [
    "# 4. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985cd9d7",
   "metadata": {},
   "source": [
    "Using ResNet 18 instead of VGG16 as paper for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b66c7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(ResNet18Classifier, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=pretrained)\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5618d066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18Classifier(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=88, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model function\n",
    "num_classes = len(unique_conditions)\n",
    "model = ResNet18Classifier(num_classes=num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50938622",
   "metadata": {},
   "source": [
    "# 5. Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd17d65",
   "metadata": {},
   "source": [
    "Including mixed precision for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de99cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device='cpu'):\n",
    "    \"\"\"\n",
    "    Train the model and validate after each epoch\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            # Handle both Subset and regular dataset formats\n",
    "            if isinstance(batch, tuple) and len(batch) == 5:\n",
    "                images, labels, _, _, _ = batch\n",
    "            else:\n",
    "                # If using a Subset, the __getitem__ might return a different format\n",
    "                images = batch[0]\n",
    "                labels = batch[1]\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()  # Ensure labels are long type for CrossEntropyLoss\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    # Handle both Subset and regular dataset formats\n",
    "                    if isinstance(batch, tuple) and len(batch) == 5:\n",
    "                        images, labels, _, _, _ = batch\n",
    "                    else:\n",
    "                        images = batch[0]\n",
    "                        labels = batch[1]\n",
    "                    \n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device).long()\n",
    "                    \n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            val_loss = val_loss / val_total\n",
    "            val_acc = val_correct / val_total\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "                  f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, '\n",
    "                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(model.state_dict(), 'fitzpatrick_model_best.pth')\n",
    "        else:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "                  f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}')\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4654797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.3995, Train Acc: 0.7471, Val Loss: 0.3808, Val Acc: 0.9005\n",
      "Epoch 2/10, Train Loss: 0.1353, Train Acc: 0.9662, Val Loss: 0.3273, Val Acc: 0.9005\n",
      "Epoch 3/10, Train Loss: 0.0511, Train Acc: 0.9879, Val Loss: 0.3211, Val Acc: 0.9039\n",
      "Epoch 4/10, Train Loss: 0.0274, Train Acc: 0.9960, Val Loss: 0.3326, Val Acc: 0.8971\n",
      "Epoch 5/10, Train Loss: 0.0153, Train Acc: 0.9978, Val Loss: 0.3453, Val Acc: 0.9074\n",
      "Epoch 6/10, Train Loss: 0.0155, Train Acc: 0.9967, Val Loss: 0.3589, Val Acc: 0.8971\n",
      "Epoch 7/10, Train Loss: 0.0096, Train Acc: 0.9985, Val Loss: 0.3755, Val Acc: 0.9022\n",
      "Epoch 8/10, Train Loss: 0.0066, Train Acc: 0.9989, Val Loss: 0.3991, Val Acc: 0.9039\n",
      "Epoch 9/10, Train Loss: 0.0332, Train Acc: 0.9908, Val Loss: 0.5088, Val Acc: 0.8937\n",
      "Epoch 10/10, Train Loss: 0.0510, Train Acc: 0.9835, Val Loss: 0.4222, Val Acc: 0.8937\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Train model\n",
    "num_epochs = 10\n",
    "model, history = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, \n",
    "    num_epochs=num_epochs, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01df2ff",
   "metadata": {},
   "source": [
    "# 6. MODEL VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19d7d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model_across_skin_types(model, test_loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate model performance across different Fitzpatrick skin types\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_skin_types = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            # Handle both Subset and regular dataset formats\n",
    "            if isinstance(batch, tuple) and len(batch) == 5:\n",
    "                images, labels, skin_types, _, _ = batch\n",
    "            else:\n",
    "                # If using a Subset, the __getitem__ might return a different format\n",
    "                images = batch[0]\n",
    "                labels = batch[1]\n",
    "                skin_types = batch[2]\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_skin_types.extend(skin_types.numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_skin_types = np.array(all_skin_types)\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = np.mean(all_preds == all_labels)\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    \n",
    "    # Calculate accuracy by skin type\n",
    "    print(\"\\nAccuracy by Fitzpatrick Skin Type:\")\n",
    "    skin_type_metrics = {}\n",
    "    for skin_type in range(1, 7):  # Fitzpatrick types 1-6\n",
    "        mask = all_skin_types == skin_type\n",
    "        if np.sum(mask) > 0:  # Only calculate if we have samples of this skin type\n",
    "            skin_type_acc = np.mean(all_preds[mask] == all_labels[mask])\n",
    "            skin_type_metrics[skin_type] = skin_type_acc\n",
    "            print(f\"  Type {skin_type}: {skin_type_acc:.4f} (n={np.sum(mask)})\")\n",
    "    \n",
    "    # Calculate accuracy for light vs dark skin\n",
    "    light_mask = all_skin_types <= 3\n",
    "    dark_mask = all_skin_types >= 4\n",
    "    \n",
    "    light_acc = 0\n",
    "    dark_acc = 0\n",
    "    \n",
    "    if np.sum(light_mask) > 0:\n",
    "        light_acc = np.mean(all_preds[light_mask] == all_labels[light_mask])\n",
    "    \n",
    "    if np.sum(dark_mask) > 0:\n",
    "        dark_acc = np.mean(all_preds[dark_mask] == all_labels[dark_mask])\n",
    "    \n",
    "    print(\"\\nAccuracy by Skin Group:\")\n",
    "    print(f\"  Light Skin (Types 1-3): {light_acc:.4f} (n={np.sum(light_mask)})\")\n",
    "    print(f\"  Dark Skin (Types 4-6): {dark_acc:.4f} (n={np.sum(dark_mask)})\")\n",
    "    \n",
    "    return {\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'skin_type_metrics': skin_type_metrics,\n",
    "        'light_skin_accuracy': light_acc,\n",
    "        'dark_skin_accuracy': dark_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55c97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5802845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model across skin types...\n",
      "Overall Accuracy: 0.9092\n",
      "\n",
      "Accuracy by Fitzpatrick Skin Type:\n",
      "  Type 1: 0.8333 (n=24)\n",
      "  Type 2: 0.8788 (n=99)\n",
      "  Type 3: 0.9200 (n=150)\n",
      "  Type 4: 0.9325 (n=163)\n",
      "  Type 5: 0.9053 (n=95)\n",
      "  Type 6: 0.8667 (n=30)\n",
      "\n",
      "Accuracy by Skin Group:\n",
      "  Light Skin (Types 1-3): 0.9020 (n=296)\n",
      "  Dark Skin (Types 4-6): 0.9167 (n=288)\n",
      "\n",
      "Summary of results:\n",
      "Overall accuracy: 0.9092\n",
      "Light vs Dark skin performance gap:\n",
      "  Gap: 0.0146 (0.9167 vs 0.9020)\n"
     ]
    }
   ],
   "source": [
    "# Validate model\n",
    "print(\"\\nValidating model across skin types...\")\n",
    "metrics = validate_model_across_skin_types(model, test_loader, device)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSummary of results:\")\n",
    "print(f\"Overall accuracy: {metrics['overall_accuracy']:.4f}\")\n",
    "print(\"Light vs Dark skin performance gap:\")\n",
    "gap = abs(metrics['light_skin_accuracy'] - metrics['dark_skin_accuracy'])\n",
    "print(f\"  Gap: {gap:.4f} ({max(metrics['light_skin_accuracy'], metrics['dark_skin_accuracy']):.4f} vs {min(metrics['light_skin_accuracy'], metrics['dark_skin_accuracy']):.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
