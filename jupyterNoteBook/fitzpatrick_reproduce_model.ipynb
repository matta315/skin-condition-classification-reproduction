{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7966577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4fc8f7",
   "metadata": {},
   "source": [
    "# 1. Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd651f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = \"../data/processed/images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a33a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to CPI\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitzpatrickDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, target_condition=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file: Path to the CSV file with annotations\n",
    "            root_dir: Directory with all the images\n",
    "            transform: Optional transform to be applied on a sample\n",
    "            target_condition: If specified, only include this skin condition\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Filter by condition if specified\n",
    "        if target_condition:\n",
    "            self.data_frame = self.data_frame[self.data_frame['label'] == target_condition]\n",
    "        \n",
    "        # Convert three_partition_label to binary (malignant vs. non-malignant)\n",
    "        self.data_frame['binary_label'] = self.data_frame['three_partition_label'].apply(\n",
    "            lambda x: 1 if x == 'malignant' else 0\n",
    "        )\n",
    "        \n",
    "        # Group skin types into light (1-3) and dark (4-6)\n",
    "        self.data_frame['skin_group'] = self.data_frame['fitzpatrick_scale'].apply(\n",
    "            lambda x: 0 if x <= 3 else 1  # 0 for light, 1 for dark\n",
    "        )\n",
    "        \n",
    "        # Create a mapping for unique conditions\n",
    "        self.unique_conditions = self.data_frame['label'].unique()\n",
    "        self.condition_to_idx = {condition: idx for idx, condition in enumerate(self.unique_conditions)}\n",
    "        \n",
    "        # Add multi-class label\n",
    "        self.data_frame['condition_idx'] = self.data_frame['label'].apply(lambda x: self.condition_to_idx[x])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        img_path = self.data_frame.iloc[idx]['image_path']\n",
    "        \n",
    "        try:\n",
    "            # Use PIL to load image\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a placeholder image if loading fails\n",
    "            image = Image.new('RGB', (224, 224), color='gray')\n",
    "        \n",
    "        # Get labels\n",
    "        binary_label = self.data_frame.iloc[idx]['binary_label']\n",
    "        skin_type = self.data_frame.iloc[idx]['fitzpatrick_scale']\n",
    "        skin_group = self.data_frame.iloc[idx]['skin_group']\n",
    "        condition_idx = self.data_frame.iloc[idx]['condition_idx']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        sample = {\n",
    "            'image': image,\n",
    "            'binary_label': binary_label,\n",
    "            'skin_type': skin_type,\n",
    "            'skin_group': skin_group,\n",
    "            'condition_idx': condition_idx\n",
    "        }\n",
    "        \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a59b3",
   "metadata": {},
   "source": [
    "# 2. DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791666b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitzpatrickDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, target_condition=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Filter by condition if specified\n",
    "        if target_condition:\n",
    "            self.data_frame = self.data_frame[self.data_frame['label'] == target_condition]\n",
    "        \n",
    "        # Group skin types into light (1-3) and dark (4-6)\n",
    "        self.data_frame['skin_group'] = self.data_frame['fitzpatrick_scale'].apply(\n",
    "            lambda x: 0 if x <= 3 else 1  # 0 for light, 1 for dark\n",
    "        )\n",
    "        \n",
    "        # Create a mapping for unique conditions\n",
    "        self.unique_conditions = self.data_frame['label'].unique()\n",
    "        self.condition_to_idx = {condition: idx for idx, condition in enumerate(self.unique_conditions)}\n",
    "        \n",
    "        # Add multi-class label\n",
    "        self.data_frame['condition_idx'] = self.data_frame['label'].apply(lambda x: self.condition_to_idx[x])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # ... rest of the code ...\n",
    "        \n",
    "        sample = {\n",
    "            'image': image,\n",
    "            'skin_type': skin_type,\n",
    "            'skin_group': skin_group,\n",
    "            'condition_idx': condition_idx\n",
    "        }\n",
    "        \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3393c",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a31e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=32, target_condition=None, max_samples=None):\n",
    "    \"\"\"\n",
    "    Load and prepare the datasets with optimization for speed\n",
    "    \"\"\"\n",
    "    # Define transforms with smaller image size\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # Smaller size for faster training\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = FitzpatrickDataset(\n",
    "        csv_file=os.path.join(DATA_PATH, 'train_split.csv'),\n",
    "        root_dir=DATA_PATH,\n",
    "        transform=transform,\n",
    "        target_condition=target_condition\n",
    "    )\n",
    "    \n",
    "    # Optionally limit the number of samples for faster training\n",
    "    if max_samples is not None and len(train_dataset) > max_samples:\n",
    "        # Get indices for stratified sampling\n",
    "        indices = []\n",
    "        labels = train_dataset.data_frame['label'].values\n",
    "        unique_labels = np.unique(labels)\n",
    "        samples_per_label = max_samples // len(unique_labels)\n",
    "        \n",
    "        for label in unique_labels:\n",
    "            label_indices = np.where(labels == label)[0]\n",
    "            if len(label_indices) > samples_per_label:\n",
    "                label_indices = np.random.choice(label_indices, samples_per_label, replace=False)\n",
    "            indices.extend(label_indices)\n",
    "        \n",
    "        # Create a subset of the dataset\n",
    "        train_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
    "    \n",
    "    val_dataset = FitzpatrickDataset(\n",
    "        csv_file=os.path.join(DATA_PATH, 'val_split.csv'),\n",
    "        root_dir=DATA_PATH,\n",
    "        transform=transform,\n",
    "        target_condition=target_condition\n",
    "    )\n",
    "    \n",
    "    test_dataset = FitzpatrickDataset(\n",
    "        csv_file=os.path.join(DATA_PATH, 'test_split.csv'),\n",
    "        root_dir=DATA_PATH,\n",
    "        transform=transform,\n",
    "        target_condition=target_condition\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders with optimization\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=4,  # Adjust based on your CPU cores\n",
    "        pin_memory=True  # Faster data transfer to GPU\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Get unique conditions (handle the case when train_dataset is a Subset)\n",
    "    if isinstance(train_dataset, torch.utils.data.Subset):\n",
    "        # Get the original dataset\n",
    "        original_dataset = train_dataset.dataset\n",
    "        unique_conditions = original_dataset.unique_conditions\n",
    "    else:\n",
    "        unique_conditions = train_dataset.unique_conditions\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, unique_conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca43ac",
   "metadata": {},
   "source": [
    "# 4. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985cd9d7",
   "metadata": {},
   "source": [
    "Using ResNet 18 instead of VGG16 as paper for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        \"\"\"\n",
    "        ResNet18-based classifier that can be used for binary or multi-class classification\n",
    "        \n",
    "        Args:\n",
    "            num_classes: Number of output classes\n",
    "            pretrained: Whether to use pretrained weights from ImageNet\n",
    "        \"\"\"\n",
    "        super(ResNet18Classifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet18 model\n",
    "        self.model = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Replace the final fully connected layer for our classification task\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # Initialize the new layer\n",
    "        nn.init.normal_(self.model.fc.weight, 0, 0.01)\n",
    "        nn.init.constant_(self.model.fc.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model:\n",
    "def create_multiclass_model(num_classes):\n",
    "    \"\"\"\n",
    "    Create a multi-class classifier model for specific skin conditions\n",
    "    \"\"\"\n",
    "    model = ResNet18Classifier(num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50938622",
   "metadata": {},
   "source": [
    "# 5. Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd17d65",
   "metadata": {},
   "source": [
    "Including mixed precision for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de99cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device='cpu'):\n",
    "    \"\"\"\n",
    "    Train the model with optimizations for speed\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    # Use mixed precision training if available\n",
    "    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            \n",
    "            # Get appropriate labels based on the task\n",
    "            if hasattr(model, 'model') and model.model.fc.out_features == 2:\n",
    "                labels = batch['binary_label'].to(device)\n",
    "            else:\n",
    "                labels = batch['condition_idx'].to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with mixed precision if available\n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward and optimize with scaling\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Standard forward and backward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(device)\n",
    "                \n",
    "                # Get appropriate labels based on the task\n",
    "                if hasattr(model, 'model') and model.model.fc.out_features == 2:\n",
    "                    labels = batch['binary_label'].to(device)\n",
    "                else:\n",
    "                    labels = batch['condition_idx'].to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'fitzpatrick_model_best.pth')\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01df2ff",
   "metadata": {},
   "source": [
    "# 6. MODEL VALIDATION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
